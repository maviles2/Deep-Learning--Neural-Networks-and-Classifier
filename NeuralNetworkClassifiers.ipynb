{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Classifiers\n",
    "## Marlene Aviles "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Neural Network Classifier with Scikit\n",
    "\n",
    "2. Neural Network Classifier with Keras\n",
    "\n",
    "3. Classifying Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re \n",
    "from numpy import loadtxt # part 2\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential # part 2\n",
    "from keras.layers import Dense # part 2\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Neural Network Classifier with Scikit\n",
    "\n",
    "Using the multi-label classifier dataset from earlier exercises (categorized-comments.jsonl in the reddit folder), fit a neural network classifier using scikit-learn. Use the code found in chapter 12 of the Applied Text Analysis with Python book as a guideline. Report the accuracy, precision, recall, F1-score, and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sports</td>\n",
       "      <td>Barely better than Gabbert? He was significant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sports</td>\n",
       "      <td>Fuck the ducks and the Angels! But welcome to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sports</td>\n",
       "      <td>Should have drafted more WRs.\\n\\n- Matt Millen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sports</td>\n",
       "      <td>[Done](https://i.imgur.com/2YZ90pm.jpg)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sports</td>\n",
       "      <td>No!! NOO!!!!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cat                                                txt\n",
       "0  sports  Barely better than Gabbert? He was significant...\n",
       "1  sports  Fuck the ducks and the Angels! But welcome to ...\n",
       "2  sports  Should have drafted more WRs.\\n\\n- Matt Millen...\n",
       "3  sports            [Done](https://i.imgur.com/2YZ90pm.jpg)\n",
       "4  sports                                      No!! NOO!!!!!"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "mlp_df = pd.read_json(\"categorized-comments.jsonl\", lines=True)\n",
    "mlp_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>2347476</td>\n",
       "      <td>4</td>\n",
       "      <td>video_games</td>\n",
       "      <td>1005720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt</th>\n",
       "      <td>2347476</td>\n",
       "      <td>2097835</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>93979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count   unique          top     freq\n",
       "cat  2347476        4  video_games  1005720\n",
       "txt  2347476  2097835    [deleted]    93979"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# N = 2347476 \n",
    "# 4 different caterogies \n",
    "mlp_df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cat\n",
       "news                       408311\n",
       "science_and_technology     158246\n",
       "sports                     775199\n",
       "video_games               1005720\n",
       "dtype: int64"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking deeper into the categories \n",
    "mlp_df[\"cat\"].unique() # selectig 4 unique cat\n",
    "mlp_df.groupby([\"cat\"]).size() # size of the cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>video_games</td>\n",
       "      <td>THAT S THE JOKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>video_games</td>\n",
       "      <td>YEAH THE PISTOL WAS DEFINITELY OP IN ME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>video_games</td>\n",
       "      <td>CHECKS AMAZON PRE ORDER DAMN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>video_games</td>\n",
       "      <td>LIKE THE OTHER USER SAID THEY CAN BE EFFECTIVE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>video_games</td>\n",
       "      <td>LAPTOPS MAYBE YOU WANT TO DOWNLOAD A GAME BEFO...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                cat                                                txt\n",
       "199995  video_games                                   THAT S THE JOKE \n",
       "199996  video_games           YEAH THE PISTOL WAS DEFINITELY OP IN ME \n",
       "199997  video_games                      CHECKS AMAZON PRE ORDER DAMN \n",
       "199998  video_games  LIKE THE OTHER USER SAID THEY CAN BE EFFECTIVE...\n",
       "199999  video_games  LAPTOPS MAYBE YOU WANT TO DOWNLOAD A GAME BEFO..."
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create function to clean text \n",
    "\n",
    "def clean_data(text):\n",
    "    \n",
    "    \"\"\"\n",
    "    Removes the punctuations,special characters, and \n",
    "    sets texts to uppercase strings using\n",
    "    RegEX Python 're' module. \n",
    "    \"\"\"    \n",
    "    text=re.sub('&lt;/?.*?&gt;',' &lt;&gt', text)\n",
    "    text=re.sub('\\\\d|\\\\W+|_',' ',text)\n",
    "    text=re.sub('[^a-zA-Z]',\" \", text)\n",
    "    text=text.upper()\n",
    "    \n",
    "    return text \n",
    "\n",
    "# Apply clean_data function to text and return clean df \n",
    "\n",
    "size = 50000 # sample sizes are not evenly distributed size of smallest sample\n",
    "replace = True  # with replacement\n",
    "fn = lambda obj: obj.loc[np.random.choice(obj.index, size, replace),:] # randomizing \n",
    "\n",
    "mlp_clean = mlp_df.groupby('cat', as_index=False).apply(fn)\n",
    "\n",
    "# replacing df with new one that is clean from punctuation\n",
    "\n",
    "del mlp_df\n",
    "\n",
    "\"\"\"\n",
    "    Applies clean_data function to txt column of mlp_df, \n",
    "    returns a clean df indexed by category.     \n",
    "\"\"\"\n",
    "\n",
    "mlp_clean['txt'] = mlp_clean['txt'].apply(lambda x:clean_data(x))\n",
    "mlp_clean.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mlp_clean.tail() # verify function was applied and worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140000, 86397)\n",
      "(60000, 86397)\n"
     ]
    }
   ],
   "source": [
    "# NLTK stop words for common english words\n",
    "from nltk.corpus import stopwords\n",
    "set(stopwords.words('english'))\n",
    "\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "# Applying stopwords to countvec to apply to txt column \n",
    "\n",
    "cv = CountVectorizer(stop_words=stopwords)\n",
    "\n",
    "# # split into input (X) and output (y) variables\n",
    "X = cv.fit_transform(mlp_clean['txt'])\n",
    "Y = mlp_clean['cat']\n",
    "\n",
    "# Test/Train split, 30/70 ratio, random state 40 for seeding \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.30, random_state=40)\n",
    "\n",
    "# Looking at dimensions of test and training \n",
    "\n",
    "print(X_train.shape); print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marleneaviles/opt/anaconda3/envs/S/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(5,5,5), activation='relu', solver='adam', max_iter=500)\n",
    "mlp.fit(X_train,y_train)\n",
    "\n",
    "predict_train = mlp.predict(X_train)\n",
    "predict_test = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MATRIX:  [[24304  3863  2091  4767]\n",
      " [10286 15918  5245  3483]\n",
      " [ 1894  5313 20985  6919]\n",
      " [ 3260  3508  9362 18802]]\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                  news       0.61      0.69      0.65     35025\n",
      "science_and_technology       0.56      0.46      0.50     34932\n",
      "                sports       0.56      0.60      0.58     35111\n",
      "           video_games       0.55      0.54      0.55     34932\n",
      "\n",
      "              accuracy                           0.57    140000\n",
      "             macro avg       0.57      0.57      0.57    140000\n",
      "          weighted avg       0.57      0.57      0.57    140000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stats on Y training \n",
    "predict_train = mlp.predict(X_train)\n",
    "predict_test = mlp.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "print(\"MATRIX: \",confusion_matrix(y_train,predict_train))\n",
    "\n",
    "print(classification_report(y_train,predict_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MATRIX:  [[10083  1798   925  2169]\n",
      " [ 4564  6514  2299  1691]\n",
      " [  923  2547  8300  3119]\n",
      " [ 1494  1770  4228  7576]]\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                  news       0.59      0.67      0.63     14975\n",
      "science_and_technology       0.52      0.43      0.47     15068\n",
      "                sports       0.53      0.56      0.54     14889\n",
      "           video_games       0.52      0.50      0.51     15068\n",
      "\n",
      "              accuracy                           0.54     60000\n",
      "             macro avg       0.54      0.54      0.54     60000\n",
      "          weighted avg       0.54      0.54      0.54     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stats on Y test \n",
    "print(\"MATRIX: \",confusion_matrix(y_test,predict_test))\n",
    "print(classification_report(y_test,predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Neural Network Classifier with Keras\n",
    "\n",
    "Using the multi-label classifier dataset from earlier exercises (categorized-comments.jsonl in the reddit folder), fit a neural network classifier using Keras. Use the code found in chapter 12 of the Applied Text Analysis with Python book as a guideline. Report the accuracy, precision, recall, F1-score, and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c anaconda nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_file(corpus):\n",
    "    \"\"\"\n",
    "    Function converts JSONL file into\n",
    "    a pandas df for easier manipulation.    \n",
    "    \"\"\"       \n",
    "    data = []\n",
    "    \n",
    "    with open('categorized-comments.jsonl', 'r') as corpus:\n",
    "        for line in corpus:\n",
    "            data.append(json.loads(line))\n",
    "\n",
    "        return pd.DataFrame(data)   \n",
    "        \n",
    "corpus_df = read_file(\"categorized-comments.jsonl\")\n",
    "corpus_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2347466</th>\n",
       "      <td>video_games</td>\n",
       "      <td>Banned with the account for 5 years. I had my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347467</th>\n",
       "      <td>video_games</td>\n",
       "      <td>Rare Replay, would love the opportunity to go ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347468</th>\n",
       "      <td>video_games</td>\n",
       "      <td>You've got to put yourself into the mindset th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347469</th>\n",
       "      <td>video_games</td>\n",
       "      <td>It helped.. That was what i was looking for. T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347470</th>\n",
       "      <td>video_games</td>\n",
       "      <td>They already sell and distribute win32 apps. T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347471</th>\n",
       "      <td>video_games</td>\n",
       "      <td>Same here I have over 100 hours of gameplay on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347472</th>\n",
       "      <td>video_games</td>\n",
       "      <td>1 might as well take a shot.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347473</th>\n",
       "      <td>video_games</td>\n",
       "      <td>My comment. Rare replay.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347474</th>\n",
       "      <td>video_games</td>\n",
       "      <td>Already posted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347475</th>\n",
       "      <td>video_games</td>\n",
       "      <td>Playstation is a bigger brand and has always h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 cat                                                txt\n",
       "2347466  video_games  Banned with the account for 5 years. I had my ...\n",
       "2347467  video_games  Rare Replay, would love the opportunity to go ...\n",
       "2347468  video_games  You've got to put yourself into the mindset th...\n",
       "2347469  video_games  It helped.. That was what i was looking for. T...\n",
       "2347470  video_games  They already sell and distribute win32 apps. T...\n",
       "2347471  video_games  Same here I have over 100 hours of gameplay on...\n",
       "2347472  video_games                       1 might as well take a shot.\n",
       "2347473  video_games                           My comment. Rare replay.\n",
       "2347474  video_games                                     Already posted\n",
       "2347475  video_games  Playstation is a bigger brand and has always h..."
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Second option to loading file by using argument lines-TRUE)\n",
    "import pandas as pd \n",
    "corpus_df = pd.read_json(\"categorized-comments.jsonl\", lines=True)\n",
    "corpus_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to clean text \n",
    "\n",
    "def clean_data(text):\n",
    "    \n",
    "    \"\"\"\n",
    "    Remove punctuations and special characters\n",
    "    from text, data converted into uppercase text using\n",
    "    RegEX Python 're' module. \n",
    "    \"\"\"    \n",
    "    text=re.sub('&lt;/?.*?&gt;',' &lt;&gt', text)\n",
    "    text=re.sub('\\\\d|\\\\W+|_',' ',text)\n",
    "    text=re.sub('[^a-zA-Z]',\" \", text)\n",
    "    text=text.upper()\n",
    "    \n",
    "    return text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>news</td>\n",
       "      <td>WELL THAT S A BIT OF A GENERALIZATION I M IN T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>news</td>\n",
       "      <td>KEEP UPVOTING PROPAGANDA REDDIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>news</td>\n",
       "      <td>NOTHING WAS ALIVE WHEN WE GOT THERE NOTHING MU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>news</td>\n",
       "      <td>NO LYING LIKE CNN AND THE NYT MAKES A PERSON O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>news</td>\n",
       "      <td>I THINK THE BY PENETRATION THING IS THE PROBLE...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cat                                                txt\n",
       "0  news  WELL THAT S A BIT OF A GENERALIZATION I M IN T...\n",
       "1  news                   KEEP UPVOTING PROPAGANDA REDDIT \n",
       "2  news  NOTHING WAS ALIVE WHEN WE GOT THERE NOTHING MU...\n",
       "3  news  NO LYING LIKE CNN AND THE NYT MAKES A PERSON O...\n",
       "4  news  I THINK THE BY PENETRATION THING IS THE PROBLE..."
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply clean_data function to text and return clean df \n",
    "\n",
    "size = 55000 # sample sizes are not evenly distributed, took average \n",
    "replace = True  # with replacement\n",
    "fn = lambda obj: obj.loc[np.random.choice(obj.index, size, replace),:] # randomizing \n",
    "\n",
    "category = corpus_df.groupby('cat', as_index=False).apply(fn)\n",
    "\n",
    "# replacing df with new one that is clean from punctuation\n",
    "\n",
    "del corpus_df\n",
    "\n",
    "\"\"\"\n",
    "    Applies clean_data function to txt column of corupus df, \n",
    "    returns a clean df indexed by category.     \n",
    "\"\"\"\n",
    "\n",
    "category['txt'] = category['txt'].apply(lambda x:clean_data(x))\n",
    "category.reset_index(drop=True, inplace=True)\n",
    "\n",
    "category.head() # verify function was applied and worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       txt\n",
       "cat       \n",
       "0    55000\n",
       "1    55000\n",
       "2    55000\n",
       "3    55000"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoding: Label versus One Hot Encoder options \n",
    "\n",
    "labelencoder = LabelEncoder() # selecting encoder\n",
    "\n",
    "cat = category[\"cat\"]\n",
    "category[\"cat\"]=labelencoder.fit_transform(cat) # applying encoder to cat column in df \n",
    "category.groupby(\"cat\").count() # groups by category total count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test/Train Split + Loading Stopwords from NLTK \n",
    "\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "set(stopwords.words('english'))\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "N_FEATURES = 5000 \n",
    "N_CLASSES = 1\n",
    "N_UNITS = 2500\n",
    "\n",
    "countvectorizer = CountVectorizer(analyzer='word',\n",
    "                     stop_words=stop_words, \n",
    "                     max_features = N_FEATURES,\n",
    "                     max_df = 0.5,\n",
    "                     min_df = 3)\n",
    "\n",
    "# # split into input (X) and output (y) variables\n",
    "X = countvectorizer.fit_transform(category['txt'])\n",
    "\n",
    "y = category['cat']\n",
    "\n",
    "\n",
    "# Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442400, 5000) (442400,) (189600,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape,y_test.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier creation with (layers and nodes selected here)\n",
    "\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding layers with Relu and Softmax activation functions \n",
    "classifier.add(Dense(units=500,activation=\"relu\",input_shape=(N_FEATURES,)))\n",
    "classifier.add(Dense(units=4, activation=\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling using .compile neural network \n",
    "classifier.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"rmsprop\", # loss method + root mean square propagation  \n",
    "                       metrics=[\"accuracy\"]) # accuaray performance metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "442400/442400 [==============================] - 128s 289us/step - loss: 0.8665 - acc: 0.6481\n",
      "Epoch 2/5\n",
      "442400/442400 [==============================] - 170s 384us/step - loss: 0.8285 - acc: 0.6654\n",
      "Epoch 3/5\n",
      "442400/442400 [==============================] - 152s 343us/step - loss: 0.8154 - acc: 0.6703\n",
      "Epoch 4/5\n",
      "442400/442400 [==============================] - 142s 322us/step - loss: 0.8040 - acc: 0.6762\n",
      "Epoch 5/5\n",
      "442400/442400 [==============================] - 152s 344us/step - loss: 0.7911 - acc: 0.6829\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d25ec6850>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying classifiers to training data, 5 interations (more iterations = better accuracy, min error)\n",
    "\n",
    "classifier.fit(X_train, y_train, batch_size=128, epochs=5, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_95 (Dense)             (None, 500)               2500500   \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 4)                 2004      \n",
      "=================================================================\n",
      "Total params: 2,502,504\n",
      "Trainable params: 2,502,504\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "189600/189600 [==============================] - 26s 137us/step\n",
      "ACCURACY (TRAINING SET): 0.6650\n"
     ]
    }
   ],
   "source": [
    "# Stats of classifiers: Confusion Matrix, Accuracy, F1- score etc.\n",
    "\n",
    "classifier.summary() \n",
    "\n",
    "loss, accuracy = classifier.evaluate(X_test, y_test, verbose=1) # eval loss testing set \n",
    "print(\"ACCURACY (TRAINING SET): {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a prediction on the classifier to get accuracy, recall, precision etc. \n",
    "y_pred = classifier.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY:  0.6650105485232067\n"
     ]
    }
   ],
   "source": [
    "print(\"ACCURACY: \", accuracy_score(y_test,y_pred)) # acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPORT:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.67      0.65     47201\n",
      "           1       0.73      0.63      0.68     47448\n",
      "           2       0.60      0.78      0.68     47629\n",
      "           3       0.73      0.59      0.65     47322\n",
      "\n",
      "    accuracy                           0.67    189600\n",
      "   macro avg       0.68      0.66      0.66    189600\n",
      "weighted avg       0.68      0.67      0.66    189600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"REPORT: \", classification_report(y_test,y_pred)) # F-1, recall, precision, support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX:  [[31489  6245  7259  2208]\n",
      " [ 8504 29914  5224  3806]\n",
      " [ 5018  1579 36930  4102]\n",
      " [ 4027  3334 12208 27753]]\n"
     ]
    }
   ],
   "source": [
    "print(\"CONFUSION MATRIX: \", confusion_matrix(y_test, y_pred)) # matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Classifying Images\n",
    "\n",
    "In chapter 20 of the Machine Learning with Python Cookbook, implement the code found in section 20.15 classify MSINT images using a convolutional neural network. Report the accuracy of your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "\n",
    "# Set that the color channel value will be first\n",
    "K.set_image_data_format(\"channels_first\")\n",
    "\n",
    "# Seeding\n",
    "np.random.seed(0)\n",
    "\n",
    "# Setting channels (pixels)\n",
    "channels = 1\n",
    "height = 28\n",
    "width = 28\n",
    "\n",
    "# Loading Target/Training from MNIST data\n",
    "(data_train, target_train), (data_test, target_test) = mnist.load_data()\n",
    "\n",
    "# Reshape TRAINING IMAGE = feautures\n",
    "data_train = data_train.reshape(data_train.shape[0], channels, height, width)\n",
    "\n",
    "# Reshape  TEST IMAGE = features\n",
    "data_test = data_test.reshape(data_test.shape[0], channels, height, width)\n",
    "\n",
    "# Rescaling pixel intensity (0 through 1)\n",
    "features_train = data_train / 255\n",
    "features_test = data_test / 255\n",
    "\n",
    "# Converting target using one-hot encoding\n",
    "target_train = np_utils.to_categorical(target_train)\n",
    "target_test = np_utils.to_categorical(target_test)\n",
    "number_of_classes = target_test.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intitating nn\n",
    "\n",
    "network = Sequential()\n",
    "\n",
    "# Convolutional layer # filters, #x# window, ReLU activation function\n",
    "network.add(Conv2D(filters=64,\n",
    "                   kernel_size=(5, 5),\n",
    "                   input_shape=(channels, width, height),\n",
    "                   activation='relu'))\n",
    "\n",
    "# Max pooling layer \n",
    "network.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Dropout layer\n",
    "network.add(Dropout(0.5))\n",
    "\n",
    "# Layer to flatten \n",
    "network.add(Flatten())\n",
    "\n",
    "# # Adding nn layers / reul activation\n",
    "network.add(Dense(128, activation=\"relu\"))\n",
    "\n",
    "# Adding dropout layer\n",
    "network.add(Dropout(0.5))\n",
    "\n",
    "# Adding nn layers / softmax activation function\n",
    "network.add(Dense(number_of_classes, activation=\"softmax\"))\n",
    "\n",
    "# Compile neural network\n",
    "network.compile(loss=\"categorical_crossentropy\",\n",
    "                optimizer=\"rmsprop\", \n",
    "                metrics=[\"accuracy\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c026def50>"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training NN \n",
    "network.fit(features_train, \n",
    "            target_train, \n",
    "            epochs=2, \n",
    "            verbose=0, # no description ouput\n",
    "            batch_size=1000, # # of observations x batch\n",
    "            validation_data=(features_test, target_test)) # Data for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 64, 24, 24)        1664      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 64, 12, 12)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64, 12, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,182,730\n",
      "Trainable params: 1,182,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "10000/10000 [==============================] - 4s 372us/step\n",
      "ACCURACY (TRAINING SET): 0.9709\n"
     ]
    }
   ],
   "source": [
    "network.summary() \n",
    "\n",
    "loss, accuracy = network.evaluate(features_test, target_test, verbose=1) # eval loss testing set \n",
    "print(\"ACCURACY (TRAINING SET): {:.4f}\".format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
